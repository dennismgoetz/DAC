{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import heapq\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dennis\\OneDrive\\Dokumente\\03_Master BAOR\\05_Kurse\\01_Business Analytics\\04_Data Analytics Challenge\\05_Scripts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Working Directory\n",
    "os.getcwd()\n",
    "path = \"C:/Users/Dennis/OneDrive/Dokumente/03_Master BAOR/05_Kurse/01_Business Analytics/04_Data Analytics Challenge/05_Scripts\"\n",
    "os.chdir(path)\n",
    "\n",
    "%cd \"C:\\Users\\Dennis\\OneDrive\\Dokumente\\03_Master BAOR\\05_Kurse\\01_Business Analytics\\04_Data Analytics Challenge\\05_Scripts\"\n",
    "ccdata = pd.read_csv('creditcard.csv')\n",
    "#ccdata = ccdata.iloc[:100000,:]\n",
    "ccdata.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euclidean_Metric(a,b):\n",
    "      dis=0\n",
    "      A = np.array(a)\n",
    "      B = np.array(b)\n",
    "      n=A.shape[0]\n",
    "      for i in range(n):\n",
    "          dis=dis+(A[i]-B[i])*(A[i]-B[i])\n",
    "      dis=np.sqrt(dis)\n",
    "      return dis\n",
    "\n",
    "samples = ccdata\n",
    "\n",
    "time_start=time.time()\n",
    "g_index=0\n",
    "wrg=0\n",
    "samples_X=samples.iloc[:,0:-1] #features\n",
    "samples_Y=samples.iloc[:,-1] #target variable\n",
    "Minority_sample=samples[samples['Class'] == 1] #minority set\n",
    "Minority_sample_X=Minority_sample.iloc[:,0:-1] #features of minority set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283823\n"
     ]
    }
   ],
   "source": [
    "Minority_X=np.array(Minority_sample_X) #features of Min set\n",
    "All_X=np.array(samples_X) #features of all samples\n",
    "n1=All_X.shape[0]-2*Minority_X.shape[0] #Anzahl aller samples - 2 * Anzahl Min samples #284807 - 2* 492 = 283823\n",
    "print(n1)\n",
    "\n",
    "# n=int((All_X.shape[0]-2*Minority_X.shape[0])/Minority_X.shape[0])\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 1: Noise filtering\n",
    "dis_matrix=np.zeros((Minority_X.shape[0],All_X.shape[0]),dtype=float) #leere Matrix (492x284807) nur trainingsdatenset\n",
    "\n",
    "for i in range(0,Minority_X.shape[0]):\n",
    "    for j in range(0,All_X.shape[0]):\n",
    "        dis_matrix[i,j]=Euclidean_Metric(Minority_X[i,:],All_X[j,:]) #berechne für jede Min instance die Eucl. distance zu allen sampels im Datensatz\n",
    "        if(dis_matrix[i,j]==0): #Eucl. distance zu sich selbst\n",
    "            dis_matrix[i,j]=999999 #Min instance darf nicht sein eigener nächster Nachbar sein\n",
    "dis_matrix=dis_matrix.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=[] #list for noise Min instances\n",
    "#print(Minority_X.shape[0])\n",
    "for i in range(Minority_X.shape[0]):\n",
    "    min_index=list(map(dis_matrix[i].index, heapq.nsmallest(1, dis_matrix[i]))) #index des nächsten Nachbarn in Zeile der aktuellen Min instance\n",
    "    #print(min_index)\n",
    "    if(samples_Y[min_index[0]]==0): #nearest neighbour ist aus Maj class -> Noise\n",
    "        d.append(i)\n",
    "Minority_X=np.delete(Minority_X,d,axis=0) #lösche alle Noise samples aus Min set\n",
    "#print(Minority_X.shape)\n",
    "n=int((n1)/Minority_X.shape[0])\n",
    "#print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Minority_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 2: Adaptive neighbor instances selection\n",
    "n = 10 #number of synthetic new instances per qualified Min instance\n",
    "k = 5\n",
    "synthetic = np.zeros(((Minority_X.shape[0])*n,Minority_X.shape[1]),dtype=float) #Matrix(qualified Min instances * n x Number of Features)\n",
    "\n",
    "#print(Minority_X.shape[0])\n",
    "for i in range(Minority_X.shape[0]):\n",
    "    min_index=list(map(dis_matrix[i].index, heapq.nsmallest(k, dis_matrix[i]))) #indizes der k nächsten Nachbarn in Zeile der aktuellen qualif. Min instance\n",
    "    best_index={}\n",
    "    best_f=0\n",
    "    for h in range(len(min_index)):\n",
    "        \n",
    "        if(samples_Y[min_index[h]]==0): #if h. nearest neighbour belongs to Maj class set -> STOP\n",
    "            best_index[best_f]=min_index[h]\n",
    "            best_f+=1\n",
    "            break\n",
    "        else:\n",
    "            best_index[best_f]=min_index[h] #else append h. nearest neighbour to set of qualified nearest neighbours for qualified Min instance\n",
    "            best_f+=1\n",
    "    #print(best_index)\n",
    "\n",
    "    # Algorithm 3: Procedure of ASN-SMOTE (Create new synthetic minority samples)\n",
    "    for j in range(0,n):\n",
    "        nn=random.randint(0,len(best_index)-1) #Zufälliges Auswählen eines besten Nachbarn aus dem Set der qualifizierten Nachbarn\n",
    "        #print(min_index[nn])\n",
    "        dif=All_X[best_index[nn]]-Minority_X[i] #Differenz des zufällig ausgewählten Nachbarn und der Min instance\n",
    "        #print(dif)\n",
    "        gap=random.random() #Wert zw. 0 und 1\n",
    "        synthetic[g_index]=Minority_X[i]+gap*dif #Generierung einer neuen Min instance\n",
    "        g_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(synthetic.shape)\n",
    "#print(wrg)\n",
    "\n",
    "# synthetic=synthetic[0:synthetic.shape[0]-,:]\n",
    "labels=np.ones(synthetic.shape[0]) #Kennzeichnung der neuen synthetischen samples als Min instance mit class=1\n",
    "synthetic=np.insert(synthetic,synthetic.shape[1],values=labels,axis=1)\n",
    "examples=np.concatenate((samples,synthetic),axis=0) #Verbindung der samples mit den synthetischen samples\n",
    "time_end=time.time()\n",
    "del(dis_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "930"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples) - len(All_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
